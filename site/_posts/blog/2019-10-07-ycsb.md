---
layout: post
title: "YCSB Benchmark with Crail on DRAM, Flash and Optane over RDMA and NVMe-over-Fabrics"
author: Patrick Stuedi and Jonas Pfefferle
category: blog
comments: true
---

<div style="text-align: justify"> 
<p>
Recently, suppport for Crail has been added to the <a href="https://github.com/brianfrankcooper/YCSB">YCSB</a> benchmark suite. In this blog we describe how to run the benchmark and briefly show some performance comparisons between Crail and other key-value stores running on DRAM, Flash and Optane such as <a href="https://www.aerospike.com">Aerospike</a> or <a href="https://ramcloud.atlassian.net/wiki/spaces/RAM/overview">RAMCloud</a>. 
</p>
</div>

### The Crail Key-Value Storage Namespace

<div style="text-align: justify"> 
<p>
Remember that Crail exports a hierarchical storage namespace where individual nodes in the storage hierarchy can have different types. Supported node types are Directory (Dir), File, Table, KeyValue (KV) and Bag. Each node type has slightly different properties and operations users can execute on them, but also restricts the possible node types of its child nodes. For instance, directories offer efficient enumeration of all of its children, but restricts children to be either of type Directory of File. Table nodes allow users to insert or retrieve KV nodes using a PUT/GET API, but restricts the children to be of type KV. All nodes, independent of their type, are identified using path names encoding the location in the storage hierarchy, similar to files and directories in a file system. All nodes further consist of metadata, managed by one of Crail's metadata servers, and an arbitrary large data sets, distributed across Crail's datanodes. 
</p>
</div>

<br>
<div style="text-align:center"><img src ="http://127.0.0.1:4000/img/blog/ycsb/storage_namespace.svg" width="400"></div>
<br> 
<br>

<div style="text-align: justify"> 
<p>
In this blog we focus on Crail's KeyValue API available to users through the Table and KV node types. Creating a new table and inserting a key-value pair into it can be done as follows.
 </p>
</div>

```
CrailStore crail = CrailStore.newInstance();
CrailTable table = fs.create("/tab1", CrailNodeType.TABLE, ..., ...).get();
CrailKeyValue kv = fs.create("/tab1/key1", CrailNodeType.KEYVALUE, ..., ...).get();
``` 

<div style="text-align: justify"> 
<p>
Here the table's name is "/tab1" and the key of the key-value pair is "key1". Unlike in a traditional key-value store where the value of a key is defined when inserting the key, in Crail the value of the key consists of an arbitrary size append-only data set, that is, a user may set the value of a key by appending data to it as follows. 
 </p>
</div>

```
CrailOutputStream stream = kv.getOutputStream();
CrailBuffer buf = CrailBuffer.wrap("data".bytes());
stream.append(buf);
``` 
<div style="text-align: justify"> 
<p>
Lookup and reading of a key-value pair is done in a similar fashion. 
 </p>
</div>

```
CrailStore crail = CrailStore.newInstance();
CrailKeyValue kv = fs.lookup("/tab1/key1").get().asKeyValue();
CrailInputStream stream = kv.getInputStream();
CrailBuffer buf = crail.createBuffer();
stream.read(buf);
``` 

<div style="text-align: justify"> 
<p>
Note that multiple clients may concurrently try to create a key-value pair with the same name in the same table. In that case Crail provides last-put-wins semantics where the most recently created key-value pair prevails. Clients currently reading or writing a stale key-value pair will be notified about the staleness of their object upon the next data access. 
 </p>
</div>
 
### Running YCSB with Crail

<div style="text-align: justify"> 
<p>
The <a href="https://github.com/brianfrankcooper/YCSB">YCSB</a> benchmark is a popular benchmark to measure the performance of key-value stores in terms of PUT/GET latency and throughput for different workloads. We recently contributed support for Crail to the benchmark are we are excited that the Crail binding got accepted and integrated into the benchmark last June. With Crail, users can now run NoSQL workloads over Crail's RDMA and NVMe-over-fabrics storage tiers. 
</p> 
</div>  

<div style="text-align: justify"> 
<p>
In order to run the benchmark simply clone the YCSB repository and build the Crail binding as follows. 
</p> 
</div>   

```
crail@clustermaster:~$ git clone http://github.com/brianfrankcooper/YCSB.git
crail@clustermaster:~$ cd YCSB
crail@clustermaster:~$ mvn -pl com.yahoo.ycsb:crail-binding -am clean package
```   

<div style="text-align: justify"> 
<p>
You need to have a Crail deployment up and running to run the YCSB benchmark. Follow the <a href="https://incubator-crail.readthedocs.io/en/latest">Crail documentation</a> if you need help with configuring and deploying Crail. Once Crail is up and accessible, data can be generated and loaded into Crail as follows. 
</p> 
</div>  

```
crail@clustermaster:~$ ./bin/ycsb load crail -s -P workloads/workloada -P large.dat -p crail.enumeratekeys=true >outputLoad.txt
```  


<div style="text-align: justify"> 
<p>
In this case we are running workload A which is an update heavy workload. Different workloads for different read/update ratios can be specified using the -P switch. The size of the data -- or more precisely -- the number of records to be written, can be defined via the YSCB property "recordcount". You can define arbitrary number of YSCB properties in a file (e.g., "large.dat") and pass the name of the file to the YSCB benchmark when loading the data. Note the Crail YCSB binding will pick up all the Crail configuration parameters defined in "$CRAIL_HOME/crail-site.conf". In the above example we further use "crail.enumeratekeys=true" which is a parameter specific to the Crail YCSB binding that enable enumeration of Crail tables. Enumeration support is convenient as it allows browsing of tables using the Crail command line tools. During actual performance measurements, however, it is recommended to run off enumeration support which is faster. 
</p> 
</div> 

<div style="text-align: justify"> 
<p>
So far we have just loaded the data. Let's now run the actual benchmark which consists of a series of read and update operations. 
</p> 
</div>  

```
crail@clustermaster:~$ ./bin/ycsb run crail -s -P workloads/workloada
```  

### YCSB Benchmark Performance for DRAM & Intel Optane

<div style="text-align: justify"> 
<p>
During the deployment of Crail, one has to decide on the storage capacity of each individual storage tier or storage class, which is a non-trivial task. One approach is to provision sufficient capacity to make sure that under normal operation the storage demands can be served by the the highest performing storage class, and then allocate additional resources in the local and disaggregated flash tiers to absorb the peak storage demands. 
</p>
</div> 

<br>
<div style="text-align:center"><img src ="http://127.0.0.1:4000/img/blog/ycsb/ycsb_get.svg" width="700"></div>
<br> 
<br>

<div style="text-align: justify"> 
<p>
Ideally, we would want individual storage tiers to be elastic in a way that storage capacities can be adjutsed dynamically (and automatically) based on the load. Currently, Crail does not provide elastic storage tiers (adding storage servers on the fly is always possible, but not removing). A recent research project has been exploring how to build elastic storage in the context of serverless computing and in the future we might integrate some of these ideas into Crail as well. Have a look at the <a href="https://www.usenix.org/system/files/osdi18-klimovic.pdf">Pocket OSDI'18</a> paper for more details or check out the system at <a href="https://github.com/stanford-mast/pocket">https://github.com/stanford-mast/pocket</a>. 
</p>
</div>  

<br>
<div style="text-align:center"><img src ="http://127.0.0.1:4000/img/blog/ycsb/ycsb_put.svg" width="700"></div>
<br> 
<br>

### Summary

<div style="text-align: justify"> 
<p>
In this blog we discussed various configuration options in Crail for deploying tiered disaggrated storage. Crail allows mixing traditional non-disaggregated storage with disaggregated storage in a single storage namespace and is thereby able to seamlessly absorb peak storage demands while offering excellent performance during regular operation. Storage classes and location classes in Crail further provide fine-grained control over how storage resources are provisoned and allocated. In the future, we are considering to make resource provisioning in Crail dynamic and automatic, similar to <a href="https://www.usenix.org/system/files/osdi18-klimovic.pdf">Pocket</a>. 
 </p>
 </div>

 
